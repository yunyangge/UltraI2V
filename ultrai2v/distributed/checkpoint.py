import os
import time

import torch
import torch.nn as nn
from safetensors.torch import load_file as safe_load
from torch.distributed.checkpoint.state_dict import (
    _init_optim_state,
    get_model_state_dict,
    get_optimizer_state_dict,
    set_model_state_dict,
    set_optimizer_state_dict,
    StateDictOptions,
)
from torch.distributed.fsdp import FSDPModule
from torch.distributed.tensor import distribute_tensor, DTensor


MODEL_CHECKPOINT = "model_state_dict.pt"
OPTIM_CHECKPOINT = "optim_state_dict.pt"
PARAMS = "params"
PREFIX = "iter_"


def get_latest_checkpoint_folder(path):
    max_num = None
    if not os.path.exists(path):
        return max_num
    for name in os.listdir(path):
        folder_path = os.path.join(path, name)
        if os.path.isdir(folder_path):
            name = name.replace(PREFIX, "")
            try:
                num = int(name)
                if max_num is None or num > max_num:
                    max_num = num
            except ValueError:
                pass  # Skip non-numeric folder names
    return max_num


class Checkpointer:
    def __init__(self, folder: str, dcp_api: bool):
        self.folder = folder
        self.dcp_api = dcp_api
        self.save_root_dir = folder
        self._last_training_iteration = get_latest_checkpoint_folder(
            self.save_root_dir
        )

    @property
    def last_training_iteration(self):
        return self._last_training_iteration
    
    @staticmethod
    def load_state_dict(model: FSDPModule, full_sd: dict, dcp_api: bool = False):
        if dcp_api:
            set_model_state_dict(
                model=model,
                model_state_dict=full_sd,
                options=StateDictOptions(
                    full_state_dict=True,
                    broadcast_from_rank0=True,
                ),
            )
            return
        meta_sharded_sd = model.state_dict()
        sharded_sd = {}
        for param_name, full_tensor in full_sd.items():
            sharded_meta_param = meta_sharded_sd.get(param_name)
            sharded_tensor = distribute_tensor(
                full_tensor,
                sharded_meta_param.device_mesh,
                sharded_meta_param.placements,
            )
            sharded_sd[param_name] = nn.Parameter(sharded_tensor)
        # choose `assign=True` since we cannot call `copy_` on meta tensor
        missing_keys, unexpected_keys = model.load_state_dict(sharded_sd, strict=False, assign=True)
        if torch.distributed.get_rank() == 0:
            print("missing_keys", missing_keys)
            print("unexpected_keys", unexpected_keys)
    
    @staticmethod
    def load_model_from_path(model: FSDPModule, model_path: str, dcp_api: bool = False):
        print(f'load model from {model_path}')
        if not model_path.endswith(".safetensors"):
            full_sd = torch.load(
                model_path, mmap=True, weights_only=True, map_location="cpu"
            )
        else:
            full_sd = safe_load(model_path, device="cpu")
        Checkpointer.load_state_dict(model, full_sd, dcp_api=dcp_api)
        del full_sd

    def load_model(self, model: FSDPModule, ema: bool = False):
        model_checkpoint = f"ema_{MODEL_CHECKPOINT}" if ema else MODEL_CHECKPOINT
        last_model_checkpoint = (
            f"{self.save_root_dir}/{PREFIX}{self.last_training_iteration:09d}/{model_checkpoint}"
        )
        print(f'resume last_model_checkpoint from {last_model_checkpoint}')
        full_sd = torch.load(
            last_model_checkpoint, mmap=True, weights_only=True, map_location="cpu"
        )
        self.load_state_dict(model, full_sd, dcp_api=self.dcp_api)
        del full_sd

    def load_optim(self, model: FSDPModule, opt: torch.optim.Optimizer):
        last_optim_checkpoint = (
            f"{self.save_root_dir}/{PREFIX}{self.last_training_iteration:09d}/{OPTIM_CHECKPOINT}"
        )
        print(f'resume last_optim_checkpoint from {last_optim_checkpoint}')
        full_sd = torch.load(
            last_optim_checkpoint, mmap=True, weights_only=True, map_location="cpu"
        )
        if self.dcp_api:
            set_optimizer_state_dict(
                model=model,
                optimizers=opt,
                optim_state_dict=full_sd,
                options=StateDictOptions(
                    full_state_dict=True,
                    broadcast_from_rank0=True,
                ),
            )
            return
        _init_optim_state(opt)
        param_groups = opt.state_dict()["param_groups"]
        state = opt.state_dict()["state"]

        full_param_groups = full_sd["param_groups"]
        full_state = full_sd["state"]

        for param_group, full_param_group in zip(param_groups, full_param_groups):
            for key, value in full_param_group.items():
                if key == PARAMS:
                    continue
                param_group[key] = value
            for pid, full_pid in zip(param_group[PARAMS], full_param_group[PARAMS]):
                if pid not in state:
                    continue
                param_state = state[pid]
                full_param_state = full_state.get(full_pid, None)
                if full_param_state is None:
                    if torch.distributed.get_rank() == 0:
                        print(f"WARN: param [{full_pid}] does NOT have param_state")
                    continue
                for attr, full_tensor in full_param_state.items():
                    sharded_tensor = param_state[attr]
                    if isinstance(sharded_tensor, DTensor):
                        # exp_avg is DTensor
                        param_state[attr] = distribute_tensor(
                            full_tensor,
                            sharded_tensor.device_mesh,
                            sharded_tensor.placements,
                        )
                    else:
                        # step is plain tensor
                        param_state[attr] = full_tensor
        opt.load_state_dict(
            {
                "param_groups": param_groups,
                "state": state,
            }
        )
        del full_sd

    def _get_full_model_state_dict(self, model: FSDPModule):
        if self.dcp_api:
            return get_model_state_dict(
                model=model,
                options=StateDictOptions(
                    full_state_dict=True,
                    cpu_offload=True,
                ),
            )

        sharded_sd = model.state_dict()
        cpu_state_dict = {}
        for param_name, sharded_param in sharded_sd.items():
            full_param = sharded_param.full_tensor()
            if torch.distributed.get_rank() == 0:
                cpu_state_dict[param_name] = full_param.cpu()
            else:
                del full_param
        return cpu_state_dict

    def _get_full_optimizer_state_dict(
        self,
        model: FSDPModule,
        opt: torch.optim.Optimizer,
    ):
        if self.dcp_api:
            return get_optimizer_state_dict(
                model=model,
                optimizers=opt,
                options=StateDictOptions(
                    full_state_dict=True,
                    cpu_offload=True,
                ),
            )
        is_rank_zero = torch.distributed.get_rank() == 0
        sharded_sd = opt.state_dict()
        sharded_state = sharded_sd["state"]
        full_state = {}
        for group_id, sharded_group in sharded_state.items():
            group_state = {}
            for attr, sharded_tensor in sharded_group.items():
                if isinstance(sharded_tensor, DTensor):
                    # "exp_avg" in AdamW is `DTensor`
                    full_tensor = sharded_tensor.full_tensor()
                else:
                    # "step" in AdamW is plain tensor
                    full_tensor = sharded_tensor
                if is_rank_zero:
                    group_state[attr] = full_tensor.cpu()
                else:
                    del full_tensor
            if is_rank_zero:
                full_state[group_id] = group_state
            else:
                del group_state
        if is_rank_zero:
            return {
                "param_groups": sharded_sd["param_groups"],
                "state": full_state,
            }
        else:
            return {}

    def save(self, model: FSDPModule, optim: torch.optim.Optimizer, iteration: int):
        model_state_dict = self._get_full_model_state_dict(model)
        optim_state_dict = self._get_full_optimizer_state_dict(model, optim)
        if torch.distributed.get_rank() == 0:
            new_training_iteration = f"{PREFIX}{iteration:09d}"
            new_checkpoint_folder = f"{self.save_root_dir}/{new_training_iteration}"
            new_model_checkpoint = f"{new_checkpoint_folder}/{MODEL_CHECKPOINT}"
            new_optim_checkpoint = f"{new_checkpoint_folder}/{OPTIM_CHECKPOINT}"
            os.makedirs(new_checkpoint_folder, exist_ok=True)
            torch.save(model_state_dict, new_model_checkpoint)
            torch.save(optim_state_dict, new_optim_checkpoint)
        del model_state_dict
        del optim_state_dict

    def save_ema_model(self, ema_model: FSDPModule, iteration: int):
        model_state_dict = self._get_full_model_state_dict(ema_model)
        if torch.distributed.get_rank() == 0:
            new_training_iteration = f"{PREFIX}{iteration:09d}"
            new_checkpoint_folder = f"{self.save_root_dir}/{new_training_iteration}"
            new_model_checkpoint = f"{new_checkpoint_folder}/ema_{MODEL_CHECKPOINT}"
            os.makedirs(new_checkpoint_folder, exist_ok=True)
            torch.save(model_state_dict, new_model_checkpoint)
        del model_state_dict